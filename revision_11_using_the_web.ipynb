{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyM17rBc7RHLnCHkXcT9aWL5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michael-borck/isys2001-revision/blob/main/revision_11_using_the_web.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using the web.\n",
        "\n",
        "The followingcode snippets to perform three common tasks on the web:\n",
        "* download data\n",
        "* extracting text\n",
        "* extracting table.\n",
        "\n",
        "\n",
        "1. Downloading CSV files using urllib (fake URL):\n",
        "\n",
        "```python\n",
        "import urllib.request\n",
        "\n",
        "url = \"http://example.com/path/to/file.csv\"\n",
        "filename = \"file.csv\"\n",
        "\n",
        "try:\n",
        "    urllib.request.urlretrieve(url, filename)\n",
        "    print(\"CSV file downloaded successfully.\")\n",
        "except urllib.error.HTTPError as e:\n",
        "    print(f\"Failed to download CSV file. Error: {e}\")\n",
        "```\n",
        "\n",
        "2. Extracting text from articles using goose3(from fake URLs):\n",
        "\n",
        "```python\n",
        "from goose3 import Goose\n",
        "\n",
        "url = \"http://example.com/article\"\n",
        "g = Goose()\n",
        "\n",
        "try:\n",
        "    article = g.extract(url=url)\n",
        "    text = article.cleaned_text\n",
        "    with open(\"extracted_text.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(text)\n",
        "    print(\"Text extracted and saved successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to extract text. Error: {e}\")\n",
        "```\n",
        "\n",
        "3. Extracting tables using pandas from Wikipedia sources:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://en.wikipedia.org/wiki/List_of_countries_by_population\"\n",
        "tables = pd.read_html(url)\n",
        "\n",
        "try:\n",
        "    for i, table in enumerate(tables):\n",
        "        table.to_csv(f\"table_{i}.csv\", index=False)\n",
        "    print(\"Tables extracted and saved successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to extract tables. Error: {e}\")\n",
        "```\n",
        "\n",
        "These code snippets demonstrate the basic functionality of each task and include basic error handling for exceptions that might occur. Remember to install the required dependencies (`goose3` and `pandas`) if you haven't already.\n",
        "\n",
        "\n",
        "Inspecting the following URLs and use the appropriate code snippet to extract text, download data, of load table int a pandas data frame.  You will need to modify the code to use the approporiate URL.  Some URLs can be used form more than one task.\n",
        "\n",
        "* https://en.wikipedia.org/wiki/List_of_countries_by_population\n",
        "* https://www.python.org/doc/essays/blurb/\n",
        "* https://github.com/datablist/sample-csv-files/raw/main/files/organizations/organizations-100.csv"
      ],
      "metadata": {
        "id": "ke2_3NmgqlNq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "foiruzF7qmSH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}